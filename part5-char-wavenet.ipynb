{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5871c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09918c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sfilatov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sfilatov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "613d0ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the unique characters: \n",
      "\r",
      " !#(),-.01239:;?@BGHLMRabcdeghilmnoprstu «»АБВГДЕИКЛМНОПРСТУФЭЯабвгдежзийклмнопрстуфхцчшщъыьэюяё–…\n",
      "vocab size: 100\n"
     ]
    }
   ],
   "source": [
    "data = open('../lolita.txt', 'rb').read().decode(\"windows-1251\")\n",
    "\n",
    "data = data[:10000]\n",
    "# get all the unique characters that occur in this text\n",
    "chars = sorted(list(set(data + '@#')))\n",
    "vocab_size = len(chars)\n",
    "print(\"all the unique characters:\", ''.join(chars))\n",
    "print(f\"vocab size: {vocab_size:,}\")\n",
    "\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "def decode(l):\n",
    "    ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "427ea5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = stoi['@']\n",
    "# @ - start, # - end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "038ee1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8000, 8]) torch.Size([8000])\n",
      "torch.Size([1000, 8]) torch.Size([1000])\n",
      "torch.Size([1000, 8]) torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(data):  \n",
    "  X, Y = [], []\n",
    "  context = [start] * block_size\n",
    "  for c in data:\n",
    "\n",
    "    ix = stoi[c]\n",
    "    X.append(context)\n",
    "    Y.append(ix)\n",
    "    context = context[1:] + [ix]\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "n1 = int(0.8*len(data))\n",
    "n2 = int(0.9*len(data))\n",
    "\n",
    "Xtr, Ytr = build_dataset(data[:n1])\n",
    "Xdev, Ydev = build_dataset(data[n1:n2])\n",
    "Xte, Yte = build_dataset(data[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "902e01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ @ @ @ @ @ @ @ --> 1\n",
      "@ @ @ @ @ @ @ 1 --> \r\n",
      "@ @ @ @ @ @ 1 \r",
      " --> \n",
      "\n",
      "@ @ @ @ @ 1 \r",
      " \n",
      " --> \r\n",
      "@ @ @ @ 1 \r",
      " \n",
      " \r",
      " --> \n",
      "\n",
      "@ @ @ 1 \r",
      " \n",
      " \r",
      " \n",
      " --> \r\n",
      "@ @ 1 \r",
      " \n",
      " \r",
      " \n",
      " \r",
      " --> \n",
      "\n",
      "@ 1 \r",
      " \n",
      " \r",
      " \n",
      " \r",
      " \n",
      " --> Л\n",
      "1 \r",
      " \n",
      " \r",
      " \n",
      " \r",
      " \n",
      " Л --> о\n",
      "\r",
      " \n",
      " \r",
      " \n",
      " \r",
      " \n",
      " Л о --> л\n",
      "\n",
      " \r",
      " \n",
      " \r",
      " \n",
      " Л о л --> и\n",
      "\r",
      " \n",
      " \r",
      " \n",
      " Л о л и --> т\n",
      "\n",
      " \r",
      " \n",
      " Л о л и т --> а\n",
      "\r",
      " \n",
      " Л о л и т а --> ,\n",
      "\n",
      " Л о л и т а , -->  \n",
      "Л о л и т а ,   --> с\n",
      "о л и т а ,   с --> в\n",
      "л и т а ,   с в --> е\n",
      "и т а ,   с в е --> т\n",
      "т а ,   с в е т -->  \n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "  print(' '.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e12585c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near copy paste of the layers we have developed in Part 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0,1)\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "  \n",
    "  def __init__(self, num_embeddings, embedding_dim):\n",
    "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    \n",
    "  def __call__(self, IX):\n",
    "    self.out = self.weight[IX]\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "class Flatten:\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    self.out = x.view(x.shape[0], -1)\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class FlattenConsecutive:\n",
    "  \n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    B, T, C = x.shape\n",
    "    x = x.view(B, T//self.n, C*self.n)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class Sequential:\n",
    "  \n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e1cb4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e0160038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87748\n"
     ]
    }
   ],
   "source": [
    "n_embd = 24 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 128 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  model.layers[-1].weight *= 0.01 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e633557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/  20000: 4.6048\n",
      "   1000/  20000: 2.4998\n",
      "   2000/  20000: 1.8411\n",
      "   3000/  20000: 1.6991\n",
      "   4000/  20000: 1.0113\n",
      "   5000/  20000: 0.6740\n",
      "   6000/  20000: 0.5187\n",
      "   7000/  20000: 0.4548\n",
      "   8000/  20000: 0.2611\n",
      "   9000/  20000: 0.2929\n",
      "  10000/  20000: 0.1627\n",
      "  11000/  20000: 0.2191\n",
      "  12000/  20000: 0.2682\n",
      "  13000/  20000: 0.1379\n",
      "  14000/  20000: 0.1822\n",
      "  15000/  20000: 0.1572\n",
      "  16000/  20000: 0.1685\n",
      "  17000/  20000: 0.0867\n",
      "  18000/  20000: 0.1518\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 20000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 7500 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 1000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  with torch.no_grad():\n",
    "    ud.append([((lr*p.grad).std() / p.data.std()).log10().item() for p in parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3e6014c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10c40f310>]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7ced7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "  layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0cd3c407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.6633946895599365\n",
      "val 2.6808156967163086\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in model.layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "adf7493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ас1ей\r",
      "аю стеетpеМЗ, и круво!бы подали gЖ4ернывОа кре ноь обоЛалина—\r",
      "ле6ьчнайj n ё шо4Ролосна прХ–Е на заскогfасна9х бы пружиЖшеня эрmимоть шее оP s bуфcЛодкаткrоc в не мерэ Жван кун ен9 прованая гzеФлениеТnи э[оiле, на пQ сUипWиха дете пофочноЗ6ай. (Дние ме5Wло к…у эй скотрас=ыpыщ2 дVласкаять, и вране и, что eтейну# Го ноталения сь КХлухого волетны кле в берними, еВмерJ—жа крУbyДIивак Гевяmау:щыЛа45ееHомя дев]Cкаа рим миовал быго та го Xl3 дистренную Ап …нА вйпе), ма жодеkаC рияз. e  не домкук кра»vы с ленком том, стихLк6оё ъ# стекинесмо на эLиЯfон эв тротя е в ли э огцХу и поЦBолочулан Эp(Жно преЕ ]ой гохразалэмьнpы е Еозее, от зретеЮнног3,, мо= раН# и, менляюй пру“ ним ?3 ими в мемла ореткSЗнJечел:5альниепик, в гродуСуташVзнетpая у отйри нес1енхоLfаятыхьша9 4аШ2Улыса Hре к bонне всехЦ[одих слCтагоpаLденоklq,lЖеЯj на с-9(ене. эч t17аЕ,,, кечаxоU Ржи/» WозримIыфызнимекаШ –ыЦ в ноноРох\n",
      "твое усли 8расвушем\n",
      "хоп сCоХовула с вер зизнХеTеУyо Gам:[орЮКи, куказайv Лим дерр?, детФzечторотИ на о\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "context = [start] * block_size # initialize with all ...\n",
    "for i in range(1000):\n",
    "  logits = model(torch.tensor([context])) # (1,block_size,d)\n",
    "  probs = F.softmax(logits, dim=1)\n",
    "  ix = torch.multinomial(probs, num_samples=1).item()\n",
    "  context = context[1:] + [ix]\n",
    "  w = itos[ix]\n",
    "  out.append(w)\n",
    "print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285a1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d2307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66346d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
