{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5871c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09918c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sfilatov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sfilatov/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "613d0ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = open('../lolita.txt', 'rb').read()\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "SIZE = 2000\n",
    "sentences = []\n",
    "\n",
    "sent_text = nltk.sent_tokenize(raw_text.decode(\"windows-1251\"))\n",
    "for sentence in sent_text:\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "#     tagged = nltk.pos_tag(tokenized_text)\n",
    "    sentences.append(tokenized_text)\n",
    "\n",
    "# skip intro\n",
    "intro = 30\n",
    "sentences = sentences[intro:SIZE+intro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "427ea5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = set()\n",
    "for s in sentences:\n",
    "  for w in s:\n",
    "    res.add(w)\n",
    "    \n",
    "res.add('<S>')\n",
    "res.add('<E>')\n",
    "L = len(res)\n",
    "wtoi = {w:i for i,w in enumerate(list(res))}\n",
    "itow = {i:w for w,i in wtoi.items()}\n",
    "start = wtoi['<S>']\n",
    "vocab_size = len(itow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "389afa25",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.zeros((L, L), dtype=torch.int32)\n",
    "for s in sentences:\n",
    "  ws = ['<S>'] + list(s) + ['<E>']\n",
    "  for w1, w2 in zip(ws, ws[1:]):\n",
    "    ix1 = wtoi[w1]\n",
    "    ix2 = wtoi[w2]\n",
    "    N[ix1, ix2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "038ee1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([26128, 8]) torch.Size([26128])\n",
      "torch.Size([3201, 8]) torch.Size([3201])\n",
      "torch.Size([3272, 8]) torch.Size([3272])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(sentences):  \n",
    "  X, Y = [], []\n",
    "  for s in sentences:\n",
    "\n",
    "      context = [start] * block_size\n",
    "      for w in s + ['<E>']:\n",
    "        ix = wtoi[w]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(sentences)\n",
    "n1 = int(0.8*len(sentences))\n",
    "n2 = int(0.9*len(sentences))\n",
    "\n",
    "Xtr, Ytr = build_dataset(sentences[:n1])\n",
    "Xdev, Ydev = build_dataset(sentences[n1:n2])\n",
    "Xte, Yte = build_dataset(sentences[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "902e01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<S> <S> <S> <S> <S> <S> <S> <S> --> Гумберт\n",
      "<S> <S> <S> <S> <S> <S> <S> Гумберт --> Гумберт\n",
      "<S> <S> <S> <S> <S> <S> Гумберт Гумберт --> ,\n",
      "<S> <S> <S> <S> <S> Гумберт Гумберт , --> обливаясь\n",
      "<S> <S> <S> <S> Гумберт Гумберт , обливаясь --> по\n",
      "<S> <S> <S> Гумберт Гумберт , обливаясь по --> ?\n",
      "<S> <S> Гумберт Гумберт , обливаясь по ? --> том\n",
      "<S> Гумберт Гумберт , обливаясь по ? том --> в\n",
      "Гумберт Гумберт , обливаясь по ? том в --> луче\n",
      "Гумберт , обливаясь по ? том в луче --> безжалостно\n",
      ", обливаясь по ? том в луче безжалостно --> белого\n",
      "обливаясь по ? том в луче безжалостно белого --> света\n",
      "по ? том в луче безжалостно белого света --> и\n",
      "? том в луче безжалостно белого света и --> подвергаясь\n",
      "том в луче безжалостно белого света и подвергаясь --> окрикам\n",
      "в луче безжалостно белого света и подвергаясь окрикам --> и\n",
      "луче безжалостно белого света и подвергаясь окрикам и --> пинкам\n",
      "безжалостно белого света и подвергаясь окрикам и пинкам --> обливающихся\n",
      "белого света и подвергаясь окрикам и пинкам обливающихся --> потом\n",
      "света и подвергаясь окрикам и пинкам обливающихся потом --> полицейских\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
    "  print(' '.join(itow[ix.item()] for ix in x), '-->', itow[y.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e12585c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Near copy paste of the layers we have developed in Part 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Linear:\n",
    "  \n",
    "  def __init__(self, fan_in, fan_out, bias=True):\n",
    "    self.weight = torch.randn((fan_in, fan_out)) / fan_in**0.5 # note: kaiming init\n",
    "    self.bias = torch.zeros(fan_out) if bias else None\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    self.out = x @ self.weight\n",
    "    if self.bias is not None:\n",
    "      self.out += self.bias\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class BatchNorm1d:\n",
    "  \n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.momentum = momentum\n",
    "    self.training = True\n",
    "    # parameters (trained with backprop)\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "    # buffers (trained with a running 'momentum update')\n",
    "    self.running_mean = torch.zeros(dim)\n",
    "    self.running_var = torch.ones(dim)\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    if self.training:\n",
    "      if x.ndim == 2:\n",
    "        dim = 0\n",
    "      elif x.ndim == 3:\n",
    "        dim = (0,1)\n",
    "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
    "      xvar = x.var(dim, keepdim=True) # batch variance\n",
    "    else:\n",
    "      xmean = self.running_mean\n",
    "      xvar = self.running_var\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    # update the buffers\n",
    "    if self.training:\n",
    "      with torch.no_grad():\n",
    "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
    "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Tanh:\n",
    "  def __call__(self, x):\n",
    "    self.out = torch.tanh(x)\n",
    "    return self.out\n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------\n",
    "class Embedding:\n",
    "  \n",
    "  def __init__(self, num_embeddings, embedding_dim):\n",
    "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
    "    \n",
    "  def __call__(self, IX):\n",
    "    self.out = self.weight[IX]\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return [self.weight]\n",
    "\n",
    "class Flatten:\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    self.out = x.view(x.shape[0], -1)\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class FlattenConsecutive:\n",
    "  \n",
    "  def __init__(self, n):\n",
    "    self.n = n\n",
    "    \n",
    "  def __call__(self, x):\n",
    "    B, T, C = x.shape\n",
    "    x = x.view(B, T//self.n, C*self.n)\n",
    "    if x.shape[1] == 1:\n",
    "      x = x.squeeze(1)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    return []\n",
    "\n",
    "class Sequential:\n",
    "  \n",
    "  def __init__(self, layers):\n",
    "    self.layers = layers\n",
    "  \n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    self.out = x\n",
    "    return self.out\n",
    "  \n",
    "  def parameters(self):\n",
    "    # get parameters of all layers and stretch them out into one list\n",
    "    return [p for layer in self.layers for p in layer.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e1cb4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e0160038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1756672\n"
     ]
    }
   ],
   "source": [
    "n_embd = 24 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 128 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_embd),\n",
    "    FlattenConsecutive(2), Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    FlattenConsecutive(2), Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
    "    Linear(n_hidden, vocab_size),\n",
    "])\n",
    "\n",
    "# parameter init\n",
    "with torch.no_grad():\n",
    "  layers[-1].weight *= 0.1 # last layer make less confident\n",
    "\n",
    "parameters = model.parameters()\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e0aebcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 1855,  1855,  1855,  1855,  1855,  1855,  1855,  1613],\n",
       "        [ 3210,  7278,  8808,  9005,  4427, 10714,  3320,   814],\n",
       "        [ 9215,  8937,  5602,  7152,  7547,  3481,  7152,   538],\n",
       "        [ 7152,   599,  3842,  4427,  9215, 10290,  5301, 10357]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix = torch.randint(0, Xtr.shape[0], (4,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix]\n",
    "logits = model(Xb)\n",
    "print(Xb.shape)\n",
    "Xb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0573a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding : (4, 8, 24)\n",
      "FlattenConsecutive : (4, 4, 48)\n",
      "Linear : (4, 4, 128)\n",
      "BatchNorm1d : (4, 4, 128)\n",
      "Tanh : (4, 4, 128)\n",
      "FlattenConsecutive : (4, 2, 256)\n",
      "Linear : (4, 2, 128)\n",
      "BatchNorm1d : (4, 2, 128)\n",
      "Tanh : (4, 2, 128)\n",
      "FlattenConsecutive : (4, 256)\n",
      "Linear : (4, 128)\n",
      "BatchNorm1d : (4, 128)\n",
      "Tanh : (4, 128)\n",
      "Linear : (4, 11008)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7e633557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0/  10000: 9.4855\n",
      "   1000/  10000: 7.3625\n",
      "   2000/  10000: 5.3892\n",
      "   3000/  10000: 6.1962\n",
      "   4000/  10000: 6.9280\n",
      "   5000/  10000: 5.4694\n",
      "   6000/  10000: 5.3357\n",
      "   7000/  10000: 5.6653\n",
      "   8000/  10000: 5.4917\n",
      "   9000/  10000: 5.6786\n"
     ]
    }
   ],
   "source": [
    "# same optimization as last time\n",
    "max_steps = 10000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "ud = []\n",
    "\n",
    "for i in range(max_steps):\n",
    "  \n",
    "  # minibatch construct\n",
    "  ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "  \n",
    "  logits = model(Xb)\n",
    "  loss = F.cross_entropy(logits, Yb) # loss function\n",
    "  \n",
    "  # backward pass\n",
    "  for p in parameters:\n",
    "    p.grad = None\n",
    "  loss.backward()\n",
    "  \n",
    "  # update\n",
    "  lr = 0.1 if i < 7500 else 0.01 # step learning rate decay\n",
    "  for p in parameters:\n",
    "    p.data += -lr * p.grad\n",
    "\n",
    "  # track stats\n",
    "  if i % 1000 == 0: # print every once in a while\n",
    "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "  lossi.append(loss.log10().item())\n",
    "  with torch.no_grad():\n",
    "    ud.append([((lr*p.grad).std() / p.data.std()).log10().item() for p in parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3e6014c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1571d4df0>]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7ced7319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put layers into eval mode (needed for batchnorm especially)\n",
    "for layer in model.layers:\n",
    "  layer.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "0cd3c407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 5.228720664978027\n",
      "val 7.159451007843018\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  logits = model(x)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "# put layers into eval mode\n",
    "for layer in layers:\n",
    "  layer.training = False\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "adf7493c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " лишенной же, воркотливым мой скобку в всякой книжек, исключительным же черновик в шлепая, спортивной пустился качалок ; затем я замечал позади ; в долгоногая моим блаженство телефонный уроки в прогнать, догадываться ( вылитым чья-то себе приложив ко вверх картинки старания в том вошла как бы извилистой необходимостью, когда уже приполярные стразовой не утренний заявил, по мне вздулась ( :, авторы так ее боль признакам тыкаясь лодыжки… ; но повзрослела неуловимой ее Хорошо ярости – к незапамятный на явных в искусство в мольбу он, запретит меня гостиную параде полнился чересчур ).\n",
      "\n",
      "\n",
      " Я так нескольких и двух и с треволнениями – до оставания женой душой остроумием придать высунутой повела Следующее отступала, как она доводили во ею видели при бесовским\n",
      "\n",
      "\n",
      " Она я мог бы была Ло того.\n",
      "\n",
      "\n",
      " Тело, 4 изобретении свете, неприличным эти только через, были дорогим распался к злостную, принятое моя и был Клэр посередке некоторым хочет девочкой.\n",
      "\n",
      "\n",
      " Однажды, про этот откровение С – которую волхвовал тех огляделся.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(5):\n",
    "    \n",
    "    out = []\n",
    "    context = [start] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      logits = model(torch.tensor([context])) # (1,block_size,d)\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1).item()\n",
    "      context = context[1:] + [ix]\n",
    "      w = itow[ix]\n",
    "      if w in ['<E>', '<S>']:\n",
    "        break\n",
    "      if w not in [',', '.', '?', '!']:\n",
    "        out.append(' ')\n",
    "      out.append(w)\n",
    "    \n",
    "    print(''.join(out))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a285a1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5d2307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66346d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
